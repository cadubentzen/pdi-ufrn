## Digital Image Processing

This website is a showcase of small projects developed during the course of Digital Image Processing offered by Universidade Federal do Rio Grande do Norte, Department of Computer Engineering.

These exercises are based on the OpenCV tutorial provided by professor Agostinho Brito Jr (http://agostinhobritojr.github.io/tutoriais/pdi/). 

OpenCV 2.4 has been used in this material.

### Negative of a region

![Negative Region](results/result_regions.png "Negative region")

This is a typical "getting started" example to OpenCV, because it uses simple pixel manipulation in order to make a negative effect in a region of the given image.

To invert the color of a pixel, the formula used is `color = 255 - color` in each channel. To run this example: `./regions <img_path> <x1> <y1> <x2> <y2>` where x1, y1, x2 and y2 the rectangular area to be turned into negative.

#### regions.cpp
```c++
{{src/regions.cpp}}
```

### Swapping regions

This example consists of swapping the four regions of a picture, given a order passed by command line. For example, running `./swap_regions lenna.png 4 3 2 1` swaps the regions as follows, since the original sequence is `1 2 3 4` (left to right, top to bottom)

![Lenna swapped](results/result_swap.png "Lenna swapped")

#### swap\_regions.cpp
```c++
{{src/swap_regions.cpp}}
```

### Counting bubbles with holes

This example makes use of `floodFill`, which consists of painting an area that has the same color, replacing it by another color. Here this technique is used for counting and labeling bubbles in a black and white picture. Besides that, in this algorithm, bubbles with holes are counted too.

Original image                                   | 
:-----------------------------------------------:|
![Original](results/result_bubbles_original.png) |

No boundaries                                              | 
:---------------------------------------------------------:|
![No boundaries](results/result_bubbles_noboundaries.png)  |

Labeled                                         |
:----------------------------------------------:|
![Labeled](results/result_bubbles_colored.png)  |


To run the program: `./bubbles <bubbles_img>`. An example is illustrated above with an example as input. First we remove the bubbles that are in the boundaries because we can't know for sure that they have holes or not (in case this picture was taken from real objects), then we paint the bubbles and bubbles with holes are paint as blue (in RGB: 0, 0, 255).

One important aspect of the algorith below is that it runs on a BGR image, not greyscale. This is done to overcome the problem of having a limit of 255 bubbles on counting if the same thing was done in greyscale. In this implementation I allowed from BGR = (0,0,1) up until BGR = (50,255,255) for labeling. This way it is possible to count up to 3276799 bubbles. The blue channel was limited to 50 for allowing bubbles with holes to be painted full blue BGR = (255,0,0) and be distinguished from the others.

#### bubbles.cpp
```c++
{{src/bubbles.cpp}}
```

### Histogram equalization

Here the histogram equalization algorithm is used with the normalized accumulated histogram to update the pixels intensity. With this algorithm, the pixel with highest intensity is going to assume the value of 255 and the others pixel also change accordingly.

![Histogram equalization](results/result_equalize.gif)

#### equalize.cpp
```c++
{{src/equalize.cpp}}
```

### Motion detection

Motion detection can also be achieved through the use of histograms. In this example, the average intensities of consecutive histograms are compared in order to determine if there was some movement in the camera stream.

![Motion detection](results/result_motion.gif)

This program can be run by `./motiondetector <threshold>`, where `<threshold>` is the relative difference to consider a moviment (value from 0 to 100). A delay of 1 second is put between each frame, because in case a too short interval was used, the difference between frames would be too little and the algorithm would not detect.

In a surveilance system, the ideal I think would be to compare frames with a background frame (empty scene) in order to determine suspecius activity with a high frame rate.

#### motiondetector.cpp
```c++
{{src/motiondetector.cpp}}
```

### Laplacian of Gaussian

Here is a comparation between the application of a Laplacian filter and the Laplacian of Gaussian. In order to obtain the Laplacian of Gaussian, the convolution of the two 3x3 kernels was calculated previously, which results in a 5x5 kernel. For this, a simple multiplication in Python with Scipy helped:

```python
import numpy as np
from scipy import signal

gauss = np.array([[1,2,1],[2,4,2],[1,2,1]])
laplacian = np.array([[0,-1,0],[-1,4,-1],[0,-1,0]])

signal.convolve2d(laplacian, gauss)

# Result:
# [[ 0, -1, -2, -1,  0],
#  [-1,  0,  2,  0, -1]
#  [-2,  2,  8,  2, -2],
#  [-1,  0,  2,  0, -1]
#  [ 0, -1, -2, -1,  0]]

```

![Laplacian of Gaussian](results/result_laplgauss.gif)

It is possible to notice that the borders now have a higher intensity, although more noise seems to show up with the Laplacian of Gaussian. It seems that due to the webcam pepper and salt noise, the gaussian filter does not help to cut it off, but rather increase its intensity.

#### laplgauss.cpp
```c++
{{src/laplgauss.cpp}}
```

### Tilt Shift

Tilt shifting consists of blurring the boundaries for selective focus, often producing miniature effect. To achieve this, element-wise multiplication is done with masks of hyperbolic tangents vertically. For example,

![Equation](results/equation_tanh.png)

and two representations of the image: focused and blurred. Afterwards, these two results are added to produce the final image, that has focus on the center and blurred at the boundaries.

![Tilt shift](results/result_tiltshift.gif)

The parameters such start of focus, decay and center of focus are controlled using GUI elements of OpenCV. Changing these values reflect in the equation for the vertical brightness of the masks.

To use this program, run `./tiltshift <img>`.

#### tiltshift.cpp
```c++
{{src/tiltshift.cpp}}
```

### Video using Tilt Shift

This is an application of the above example, where every frame of the video is processed using tilt shift, hue saturation and also frames are discarded to create a stop motion effect. An example can be seen in <https://youtu.be/Nb5tOemIDl0>.

To run this program: `./tiltshiftvideo <video_input> <video_output> <start_focus> <decay> <center_focus> <hue_offset> <num_frame>`, where `<video_output>` must have .avi extension due to the codec used. `<start_focus>`, `<decay>` and `<center_focus>` can go between 0 a 100. `<hue_gain>` can be between 0 and 255. Every `<num_frame>` one frame is gotten, so if  `<num_frame>` is 1, the video will have the same speed as the original.

To merge audio and video in the output file, I used ffmpeg to extract the track from the original clip and mix with the output video:

```
$ fmpeg -i china.mp4 -vn -acodec copy audio-china.aac 
$ ffmpeg -i china_output_hue.avi -i audio-china.aac -codec copy -shortest china_output_hue_audio.avi
```

#### tiltshiftvideo.cpp
```c++
{{src/tiltshiftvideo.cpp}}
```

### Homomorphic filter

Homomorphic filters are filters that operate in the frequency domain, based on the separation of reflectance and illumance and using a modified Gaussian filter for regulating illumination in scene.

The result below shows the application of a homomorphic filter, with source code displayed as well.

![Homomorphic](results/result_homomorphic.gif)

#### homomorphic.cpp
```c++
{{src/homomorphic.cpp}}
```
